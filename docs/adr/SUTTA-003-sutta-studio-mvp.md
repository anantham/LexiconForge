# SUTTA-003: Sutta Studio MVP + Deep Loom IR + Compiler Pipeline

**Date:** 2026-01-26  
**Status:** Accepted  
**Authors:** Aditya + Codex

## Context

LexiconForge currently renders chapters in a ‚ÄúReader‚Äù mode optimized for flow reading.  
We want a dedicated full-screen **Sutta Studio** for embodied study of the Dhamma:

- quiet UI, minimal chrome
- polysemy is a first-class feature (click words ‚Üí rotate senses)
- English scaffolding (‚Äúghost words‚Äù) is shown as a UI artifact, not source truth
- morphology is visible on interaction (word parts + inflection cues)
- grammar relations appear on interaction, not constantly

InterfaceIdea proved the UI mechanics with a static dataset, but the dataset must become dynamic:
- SuttaCentral is canonical
- analysis is generated by an LLM pipeline into a structured IR
- IR can be rerun later as models improve

## Goals (MVP)

- Dedicated `/sutta/:uid` route (full-screen, scrollable, calm).
- SuttaCentral only (no general chapter support yet).
- English visible by default.
- Ghost words always visible at ~30% opacity, non-selectable.
- Polysemy rotator + ripple adjustments always enabled.
- Morphology segmentation included (even if imperfect).
- Grammar palette + relation tethers behind a single toggle (default ON).
- Replace hardcoded DATASET with a loader that consumes IR JSON.

## Non-Goals (Deferred)

- Always-on grammar graphs
- ‚ÄúBiological jigsaw‚Äù connector shapes
- Automated citation retrieval (store citation IDs only)
- Cross-sutta linking / parallels map
- Multi-chapter stitching and retrieval augmentation

## Decision

### UI Integration
- Implement Sutta Studio as a dedicated route: `/sutta/:uid`.
- Reader may provide a minimal entry point (‚ÄúOpen in Sutta Studio‚Äù) later.
- No settings gear in the MVP. One toggle only (unlabeled).

### Data Model
- **Hybrid IR**:
  - Canonical source segments keyed to SuttaCentral segment IDs (immutable text).
  - Derived ‚Äúphase views‚Äù (Deep Loom) for UI rendering.
- IR is embedded inside Chapter records (MVP).
- Citations live in a separate registry; senses reference citation IDs.

### LLM Pipeline
Use CSP-style compiler pipeline:  
**Skeleton ‚Üí Phase Deltas ‚Üí Validator**

1) **Skeleton pass**: phases, anchors, ghost scaffolding, rough senses.  
2) **Phase deltas**: segmentation, senses, relations, ripple rules.  
3) **Validator**: repair references, enforce schema, list unresolved.

## Options Considered

### UI Location
A) Embed in Reader  
Pros: fewer routes  
Cons: overwhelms flow reading  

B) Reader mode toggle  
Pros: single page  
Cons: still mixes ‚Äústudy cockpit‚Äù into reading  

C) Dedicated route (Chosen)  
Pros: clean separation; studio can be bold without clutter  
Cons: requires routing + loader

### IR Shape
A) Phase-first only (mirror UI)  
Pros: fastest to ship  
Cons: poor canonical alignment; hard to reuse  

B) Segment-first only (canonical)  
Pros: stable  
Cons: UI projection is harder  

C) Hybrid (Chosen)  
Pros: stable source alignment + UI-friendly derived views  
Cons: needs projection + mapping metadata

### Pipeline Shape
A) Single-pass compilation  
Pros: simplest  
Cons: weaker coherence, harder to debug  

B) Skeleton ‚Üí Deltas ‚Üí Validator (Chosen)  
Pros: coherent, incremental, debuggable, rerunnable  
Cons: more orchestration  

C) Clause microcalls + linker  
Pros: maximum control  
Cons: expensive and complex for MVP

## Consequences

### Positive
- Minimal, elegant study experience without cluttering the main reader.
- IR can be regenerated as models improve.
- Pipeline is incremental and debuggable.

### Negative
- Chapter schema grows; export/import may require a migration path.
- MVP is limited to SuttaCentral.
- Embedded IR increases chapter payload size.

## Implementation Plan (MVP)

1) Add `/sutta/:uid` route and mount the Sutta Studio engine.  
2) Modularize InterfaceIdea into reusable components and types.  
3) Add IR loader (embedded in Chapter) and render the derived phase view.  
4) Stub compiler pipeline (skeleton ‚Üí deltas ‚Üí validator) for later connection.  

## Risks & Mitigations

- **Coherence drift across incremental calls**  
  Mitigate with CSP + validator pass.

- **Hallucinated citations**  
  Store only citation IDs; retrieval is a later pass.

- **Latency/cost**  
  Cache compiled packets and rerun only when needed.

## Success Criteria (MVP)

- A SuttaCentral sutta renders in Sutta Studio with:
  - Pali line, English scaffold, polysemy rotator + ripples.
  - Ghost words always visible at ~30% opacity.
  - Grammar toggle reveals suffix coloring, tooltips, and relation tethers.
- IR is dynamically loaded (not hardcoded), and rerunnable later by compiler version.

## Related Docs
- `interfaceIdea.tsx` (prototype UI)
- `docs/sutta-studio/IR.md`
- `docs/ARCHITECTURE.md`
- `docs/WORKLOG.md`

---

## Amendment ‚Äî 2026-01-28: Assembly-Line Compiler & Phase State Envelope

**Status:** Accepted  
**Authors:** Aditya + Codex  
**Scope:** Compiler pipeline + prompt contracts (quality-first rework)

### Rationale
The current phase pass asks the model to segment, define, weave English, and layout in one call. This overloads small/fast models and suppresses polysemy. We adopt a sequential assembly-line pipeline that isolates roles, preserves ambiguity, and keeps JSON outputs small and strict.

### Decision
#### Pipeline Shape (updated)
Replace "Skeleton ‚Üí Phase Deltas ‚Üí Validator" with:
1) **Skeleton (chunked)**: phase segmentation only, using 50‚Äësegment windows to avoid truncation.  
2) **Anatomist**: Pali word segmentation + morphology + relations (no meanings, no English).  
3) **Lexicographer**: contextual senses only (content words = 3 senses, function words = 1‚Äì2).  
4) **Weaver**: English mapping only (token-indexed, ghost words permitted).  
5) **Typesetter**: layoutBlocks only (uses relations + englishStructure).  
6) **Validator**: full schema validation after Lexicographer/Weaver, with light checks between passes.

#### Prompt Discipline
- All passes include a **Phase State Envelope** (plain text) stating current stage, completed steps, and invariants.  
- Each pass is a single‚Äërole specialist; no parallelization (sequential handoff only).  
- Output format uses **JSON Schema structured outputs**; Zod is used only for developer ergonomics (converted to JSON Schema).

#### Schema & Data Contract Updates
- **Flatten Pass A**: separate `words`, `segments`, `relations` arrays to lower JSON nesting and error rate.  
- **Surface consistency rule**: concatenated segments must equal surface text exactly.  
- **Polysemy contract**: content words always return 3 senses; function words return 1‚Äì2.  
- **Ripples**: explicit `ripples` map used to override ghost words when a sense changes grammar.  
- **Weaver** consumes tokenized English input and returns token indices to prevent rewording drift.  
- **Typesetter** outputs layoutBlocks as a hint; UI keeps deterministic fallback if layout fails.

### UX Implications
- Cyclable indicator is driven by `senses.length > 1`, making polysemy visible.  
- Progress UI shows granular stages (anatomizing ‚Üí glossing ‚Üí weaving ‚Üí typesetting).  
- Intermediate results are cached per phase to avoid wasted compute on refresh.

### Risks & Mitigations
- **Error propagation from Pass A**: add handoff confidence + segmentation flags; allow targeted re-run of failed words.  
- **Latency**: accept longer build times; surface precise progress states and cache per-pass outputs.  
- **Ghost word precision**: link ghosts to word IDs (stable), not segment IDs (fragile).

### Notes
This amendment aligns the compiler pipeline with the **Indra's Net** vision: preserving ambiguity, revealing structure, and avoiding forced fluency. It is a deliberate shift toward depth over speed.

---

## Amendment ‚Äî 2026-01-30: Tooltip & Content Quality Guidelines

**Status:** Accepted
**Authors:** Aditya + Claude
**Scope:** Standards for morpheme segmentation, tooltips, and grounding in source data

### Rationale
During manual validation of the MN10 demo, we identified patterns that make tooltips more engaging and accurate. These guidelines prevent hallucination and ensure content is both pedagogically useful and aesthetically clean.

### Decision

#### 1. Ground Truth Sourcing
All content must be grounded in verifiable sources:
- **Canonical text**: Fetch from SuttaCentral bilara-data API before segmentation
- **Dictionary**: Use `/api/dictionary_full/{word}` for meanings, etymology, grammar
- **Explicit sourcing**: When validating, show canonical text + dictionary data side-by-side

#### 2. Text Integrity Rule
**Concatenated segments must exactly match canonical text.**

| Wrong | Right |
|-------|-------|
| `kuru` + `su` ‚Üí "kurusu" | `kur≈´` + `su` ‚Üí "kur≈´su" |
| `bhaga` + `v` + `ƒÅ` ‚Üí "bhagavƒÅ" | `bhaga` + `vƒÅ` ‚Üí "bhagavƒÅ" |

Show the **surface form** in segments, not underlying phonology. If sandhi/lengthening occurs, reflect it in the segment text.

#### 3. Clean Segmentation
Prefer fewer, meaningful segments over hyper-granular splits:

| Avoid | Prefer |
|-------|--------|
| `vi` + `har` + `a` + `ti` (4 segments) | `vi` + `har` + `ati` (3 segments) ‚Äî unless each part needs a tooltip |
| `bhaga` + `v` + `ƒÅ` (3 segments) | `bhaga` + `vƒÅ` (2 segments) ‚Äî cleaner, `-vƒÅ` is the surface form |

Rule of thumb: If a segment would have no meaningful tooltip, merge it.

#### 4. Grammar Terms Toggle
Technical grammar terms are **gated behind a settings toggle** (default: OFF).

**How it works:**
- Write tooltips with terms in `[brackets]`: `"[Nominative] Subject ‚Äî who does the action"`
- When toggle OFF: brackets stripped ‚Üí `"Subject ‚Äî who does the action"`
- When toggle ON: full text shown ‚Üí `"[Nominative] Subject ‚Äî who does the action"`

**Examples:**
```
"[Locative] Place ‚Äî where it happened"     ‚Üí "Place ‚Äî where it happened"
"[Emphatic particle] Adds weight, 'indeed'" ‚Üí "Adds weight, 'indeed'"
"[Accusative of Time] Tells us 'when'"      ‚Üí "Tells us 'when'"
```

**Rationale:** Plain language by default for accessibility. Learners who want to build grammar vocabulary can opt in.

#### 5. Tooltip Content Hierarchy
Each tooltip should prioritize:
1. **What it means** (first line)
2. **Why it matters** (context, function in sentence)
3. **Etymology/grammar** (optional, for curious learners)

Example:
```
Good:
- "Fortune, good luck"
- "From ‚àöbhaj: to share"

Bad:
- "From ‚àöbhaj (j ‚Üí g phonetic shift in Pali derivatives)"
- "Nominal stem with possessive suffix -vant in contracted form"
```

#### 6. Engaging Details Win
Include memorable context that aids retention:
- Place names: "One of 16 Great Nations, near modern Delhi"
- Etymology stories: "Where the man-eating ogre was tamed"
- Grammatical insights: "Pali uses present tense to tell past events"

#### 7. Refrain Consistency
Words marked with `refrainId` (e.g., bhagavƒÅ, bhikkhu) should have consistent segmentation and tooltips across all phases. Update all occurrences together.

### Validation Workflow
When creating or validating demo content:
1. Fetch canonical segment from bilara-data
2. Fetch dictionary entries for each word
3. Present both sources explicitly before proposing segmentation
4. Check: do concatenated segments match canonical text exactly?
5. Check: are tooltips jargon-free and engaging?

### Notes
These guidelines emerged from hands-on validation of Phases A‚ÄìF of the MN10 demo. They prioritize learner experience over linguistic completeness.

---

## Amendment ‚Äî 2026-01-31: Benchmark Philosophy & Quality-Based Scoring

**Status:** Accepted
**Authors:** Aditya + Claude (Opus)
**Scope:** Benchmarking approach, settings documentation, quality metrics

### Rationale

During manual inspection of benchmark outputs, we discovered a fundamental mismatch: the benchmark was comparing AI-generated phase structures against hand-crafted golden phases as if they should match exactly. This is the wrong framing.

**Key Insight:** The skeleton pass makes pedagogical choices about how to slice text into phases. These choices are *creative*, not *deterministic*. An AI might legitimately split a segment differently than the golden data‚Äîthis isn't an error, it's an alternative valid approach.

The goal of Sutta Studio is to produce a **learning artifact** that helps someone understand the Pali. The golden data is one excellent way to achieve this, but not the only valid way.

### Decision

#### 1. Benchmark Philosophy: "Let the AI Cook"

**Old approach (problematic):**
- Compare AI output structure to golden structure
- Mark as "degraded" if phase boundaries differ
- Exact match = success

**New approach (adopted):**
- Validate structural integrity (no broken JSON, no missing fields)
- Score *quality* of the output on its own merits
- Accept that AI may slice differently‚Äîevaluate whether the result is useful

The question changes from "Does this match golden?" to "Would a learner understand the Dhamma from this?"

#### 2. Quality Scoring Dimensions

Instead of binary pass/fail, score each output across these dimensions:

| Dimension | Pass | What We Measure |
|-----------|------|-----------------|
| **Pali Coverage** | Skeleton | All canonical text accounted for? No dropped words? |
| **Phase Coherence** | Skeleton | Each phase is a meaningful unit? No mid-sentence cuts? |
| **Text Integrity** | Anatomist | Concatenated segments === surface form? |
| **Segmentation Quality** | Anatomist | Meaningful morpheme boundaries? Not over-split? |
| **Tooltip Richness** | Anatomist | Has etymology, grammar, context? Follows hierarchy? |
| **Sense Coverage** | Lexicographer | 3 senses for content words, 1-2 for function? |
| **Sense Appropriateness** | Lexicographer | Contextually relevant? Varied nuances? |
| **Alignment Completeness** | Weaver | All Pali words have English mappings? |
| **No Duplicate Mappings** | Weaver | No segment linked by multiple English tokens? |
| **Ghost Word Accuracy** | Weaver | Required structural words marked as ghosts? |
| **English Coherence** | Weaver | Word order makes sense? Readable? |
| **Block Logic** | Typesetter | Related words grouped? Follows grammar relations? |
| **Block Size** | Typesetter | Max 5 words per block respected? |

#### 3. Structural Validation vs Quality Scoring

Keep these separate:

**Structural Validation** (binary, catches broken output):
- JSON parses correctly
- Required fields present
- IDs are unique and reference correctly
- Segment concatenation matches surface

**Quality Scoring** (continuous, measures usefulness):
- Scores 0-1 for each dimension above
- Aggregated per-pass and per-phase
- Visualized across models for comparison

A phase can be "valid" (passes structural checks) but have low quality scores.

#### 4. Settings Panel Features

The following UI toggles are available in `SettingsPanel.tsx`. All affect rendering, not data:

| Setting | Default | Description |
|---------|---------|-------------|
| `tooltips` | ON | Show tooltips on hover/click |
| `emojiInTooltips` | ON | Include emoji in tooltip text (üéØ, üò¢, etc.) |
| `grammarTerms` | OFF | Show `[bracketed]` grammar terms in tooltips |
| `grammarArrows` | ON | Show relation arrows between words |
| `refrainColors` | OFF | Highlight words with same `refrainId` |
| `alignmentLines` | ON | Show Pali-English alignment connectors |
| `ghostWords` | ON | Show ghost words at 30% opacity |

**Content implications:**
- Tooltips should include emoji when `emojiInTooltips` is ON
- Grammar terms should use `[bracket]` format so they can be stripped when toggle is OFF
- Refrain words should have consistent `refrainId` assignments across phases

#### 5. Skeleton Divergence is Expected

The demo packet (`demoPacket.ts`) represents hand-crafted, pedagogically optimized phases. When the AI generates its own skeleton:

- Phase boundaries may differ
- Phase count may differ
- Word groupings may differ

**This is acceptable** as long as:
1. All canonical text is covered
2. Each phase is coherent (not mid-sentence)
3. Downstream passes produce quality output

**Implication for benchmarking:** Don't compare AI phases to golden phases by ID. Instead:
- Validate skeleton structure independently
- Run anatomist/lexicographer/weaver/typesetter on AI's phases
- Score quality of final output

#### 6. Known Structural Issue: Shared Segments

**Finding:** 35 of 51 phases in the golden fixture share a `canonicalSegmentId` with other phases (e.g., 7 phases all reference `mn10:2.1`). Without `wordRange` metadata, the benchmark gives all these phases the full segment text instead of their intended slice.

**Affected segments:**
- `mn10:1.2` ‚Üí 3 phases (phase-b, c, d)
- `mn10:2.1` ‚Üí 7 phases (phase-1 through 7)
- `mn10:3.2` ‚Üí 4 phases (phase-y, z, aa, ab)
- Plus 7 more segments with 3 phases each

**Resolution options:**
1. Add `wordRange: [start, end]` to phase metadata for sub-segment slicing
2. Embed `paliText` directly in phase metadata
3. Accept that live-mode skeleton will slice differently anyway

Given the "let the AI cook" philosophy, option 3 is acceptable for live-mode benchmarks. For fixture-mode (testing individual passes with curated input), option 1 or 2 should be implemented.

### Implications

1. **Benchmark reports** should show quality scores, not just pass/fail
2. **"Degraded" flag** means structural validation failed, not "differs from golden"
3. **Model comparison** should rank by quality scores across dimensions
4. **Future work**: LLM-as-judge for semantic quality, embedding similarity for senses

### Notes

This amendment reflects insights from hands-on inspection of Gemini-2-flash, Trinity-large, and other models across 15+ phases. The key realization: translation is creative, and rigid exact-match scoring misses the point of what we're building.
